{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "import threading\n",
    "import atexit\n",
    "import sounddevice as sd\n",
    "import noisereduce as nr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for audio stream configuration\n",
    "FORMAT = pyaudio.paInt16  # Sample format (16-bit)\n",
    "CHANNELS = 1             # Number of audio channels (1 for mono, 2 for stereo)\n",
    "# RATE = 44100             # Sample rate (samples per second)\n",
    "CHUNK_SIZE = 44100        # Number of audio frames per buffer\n",
    "RATE = 16000             # Sample rate (samples per second)\n",
    "\n",
    "DETECT_THRESHOLD = 800   # Threshold to detect a clap\n",
    "DETECT_DURATION = 0.5    # Time in seconds to detect a clap\n",
    "RECORD_DURATION = 10      # Time in seconds to record audio after clap is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input_queue = Queue(maxsize=2)\n",
    "stop_record_event = threading.Event()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0 -1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "detecting: 1\n",
      "[-1  0  0  0  0  0 -1  0  0  0  0  0  0 -1  0  0  0  0  0  0]\n",
      "detecting: 1\n",
      "[ 0  0  0  0  0  0  1  0  0  0  0  0  0 -1  0  0 -1  0  0 -1]\n",
      "detecting: 1\n",
      "[ 0  0  1  0  0  0  1 -1 -1  1  0  0  0 -1  0  0  1  0  0  0]\n",
      "detecting: 1\n",
      "[ 0  0  0 -1  1  1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "detecting: 1\n",
      "[0 1 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 0 0 0]\n",
      "detecting: 1\n",
      "[0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0]\n",
      "detecting: 1\n",
      "[ 0  0  1  0  0  0  0  0  0  0  1  0  0  0  0  0  0 -1  0  0]\n",
      "detecting: 1\n",
      "[ 1 -1  0  0  1  1  0  0  1  0  0  1  0  0  1  0  1  0  0  0]\n",
      "detecting: 2\n",
      "[-2 -1 -1 -1 -1 -1  0 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "detecting: 1\n",
      "[-1  0  0 -1 -1  0 -1  0 -1  0 -1 -1  0 -1  0  0  1 -1  0  1]\n",
      "detecting: 1\n",
      "[-2 -2 -2 -2 -1  0 -1 -1 -1 -1 -2 -1 -2 -2 -2 -1 -1 -3 -2 -3]\n",
      "detecting: 2\n",
      "[-1  0 -1 -1  0  1 -1 -1 -1  1  1  1  0 -2  0 -2  1 -1 -1 -1]\n",
      "detecting: 2\n",
      "[-2 -4 -4 -3 -4 -4 -2 -3 -4 -2 -4 -4 -3 -4 -3 -3 -2 -3 -1 -2]\n",
      "detecting: 3\n",
      "[ 1  3  0  0  3  4 -1  2  1  1  4  3  2  0  3  4  3 -1  1  1]\n",
      "detecting: 5\n",
      "[ -6  -6  -7  -4  -5  -4  -1  -8  -8  -7  -8  -6  -6 -12  -7  -5  -6  -6\n",
      "  -6  -7]\n",
      "detecting: 3\n",
      "[ 1  2 -4 -2 -1 -7  1 -2 -2  4 -2 -1 -1  2 -1 -2  2  2 -3 -2]\n",
      "detecting: 6\n",
      "[-1  0 -4 -6 -9 -5 -1 -4 -5 -7 -4 -1 -3  0  2 -1  1  3  0  6]\n",
      "detecting: 17\n",
      "[-1  8  3  6  1  8 16  6  9 14  9  8 16  5  4  4  1  7 12  7]\n",
      "detecting: 19\n",
      "[ -6  -3  -4  -2  -1  -6  -5  -7 -10  -3  -8  -9  -3 -16  -3  -6 -10  -4\n",
      "   0   1]\n",
      "detecting: 17\n",
      "[  6  11   8   0   1  11   8   6   6   7   1  -4   0  -1 -10  -4  -4   5\n",
      "   6   0]\n",
      "detecting: 13\n",
      "[ -6  -4  -5  -4 -12 -16 -20 -19 -11 -12  -9 -13 -12   4  -2  -9 -11 -11\n",
      " -20 -17]\n",
      "detecting: 13\n",
      "[  1   7   0 -10 -11  -6  -4   1   4 -11  -5  -6  -6  -5   1   1   9  -4\n",
      "  -5   2]\n",
      "detecting: 26\n",
      "[-29 -18 -37 -33 -24 -20 -26 -19 -24 -23 -35 -23 -24 -14 -21 -16 -14 -11\n",
      "   1   2]\n",
      "detecting: 40\n",
      "[17 40 22 -4 11 15 19 27 30 16 15 26 15  9 30 24 17  5 16 27]\n",
      "detecting: 40\n",
      "[24 33 37 23  9 26 24 24  7 25 26 26 49 35 14 32 31 28 53 24]\n",
      "detecting: 96\n",
      "[67 79 78 87 68 60 87 89 64 89 73 65 78 70 80 64 49 45 47 58]\n",
      "detecting: 97\n",
      "[ 46  41  41  22   8   7  28  27  15  -5  14  16  -2  -3  11   5 -19 -11\n",
      " -14   3]\n",
      "detecting: 80\n",
      "[ 14  16  47  19  -7   1   5  -8   4   7 -24  -1   0 -16 -23 -24 -15  -9\n",
      " -30 -42]\n",
      "detecting: 68\n",
      "[31 25 30 52 57 25 58 54 26 50 30 27 30 40 12 24 30 34 46 19]\n",
      "detecting: 63\n",
      "[-40 -55 -41 -52 -53 -54 -69 -84 -78 -44 -12 -63 -52 -40 -62 -30 -53 -46\n",
      " -61 -47]\n",
      "detecting: 58\n",
      "[57 43 -1 40 41 27 47 53 45 29 62 57 20 34 34 53 20  5  5 15]\n",
      "detecting: 71\n",
      "[ 11 -14  40  19  42  38 -19   3  13  -3  -9 -15  13   8 -17  18  39  14\n",
      "  29   2]\n",
      "detecting: 42\n",
      "[-63 -60 -84 -87 -62 -59 -35 -67 -48 -41 -69 -55 -92 -77 -36 -47 -88 -80\n",
      " -60 -47]\n",
      "detecting: 8\n",
      "[-62 -52 -50 -53 -32 -51 -42 -41 -12 -56 -25 -46 -51 -16 -28 -12 -25 -45\n",
      " -28 -47]\n",
      "detecting: 80\n",
      "[ -61  -57  -40  -91  -48  -63  -88  -66  -67  -46 -119  -95  -20  -34\n",
      "  -50  -42  -48  -16  -16  -49]\n",
      "detecting: 51\n",
      "[  4  33  41   5  59  76  16 -19  -9 -15  22  12  65  61  67  44  94  30\n",
      "  42  35]\n",
      "detecting: 94\n",
      "[-61 -73 -37 -10 -64 -58 -48 -32 -31 -63 -65 -88 -60 -72 -89 -56 -64 -58\n",
      " -21 -22]\n",
      "detecting: 67\n",
      "[ -59  -91 -101 -118  -94  -97  -39  -52  -15  -38  -12  -50  -43  -46\n",
      "  -56  -33  -36  -19  -49  -67]\n",
      "detecting: 208\n",
      "[ 92  63   0  62  13  60  50  17 126  32  49  60   6  84  -7 -13  68 -36\n",
      " -38 -59]\n",
      "detecting: 127\n",
      "[ 73  58 136  75  44 101  36  44  99 104 176  89  28  79  11  86 115 104\n",
      "  85  41]\n",
      "detecting: 176\n",
      "[-57 -41  25 -14  46  43 -20 -30 -31  60  16  49  46  38  78  98 -25  40\n",
      "  52   1]\n",
      "detecting: 98\n",
      "[-131 -130 -127  -47 -147 -147 -163 -154 -159 -139 -207 -146 -111 -103\n",
      "  -49 -110 -202 -153 -135 -140]\n",
      "detecting: 112\n",
      "[  39  -71   -7  -24  -42   51  -21  -86  -13  -71  -83  -57  -48  -34\n",
      " -113  -81  -52 -107  -81  -47]\n",
      "detecting: 72\n",
      "[ 69  61  99  49  64  57  37  75  13   1  -8 -18  40  96  18  76  59  93\n",
      "  66  -3]\n",
      "detecting: 185\n",
      "[192  90 149 114 100 178 150 181 136 104 131 156 151  53 139  84 111 152\n",
      "  77 129]\n",
      "detecting: 229\n",
      "[ 60  44  31  29  68  55  30  45  37  47 -13 -42 -30  20  79  55  67  67\n",
      "  71  27]\n",
      "detecting: 326\n",
      "[142 157 143 157 195 166 166 171 185 175 170 187 228 258 159 190 210 142\n",
      " 163 206]\n",
      "detecting: 267\n",
      "[158 113  48 152 134  86  53  83  90  -5  91  41  65  89 148 106  53  60\n",
      "  53  57]\n",
      "detecting: 255\n",
      "[168 102 141 179  64 167 104 117  40  99 127  99 221 132 148 158  85  96\n",
      "  65  52]\n",
      "detecting: 221\n",
      "[-48   9 -53 -25  23   7  67  16  75  41 113 117 -23  43  53  23  61 110\n",
      "  32  60]\n",
      "detecting: 316\n",
      "[168 236 229 140 151 265 271 148 191 166 239 236 248 261 187 229 158 233\n",
      " 212 133]\n",
      "detecting: 271\n",
      "[ 98 101  89 115 153 129 124  67  22  16  55  76  67  62  58  27  77 111\n",
      "  22  76]\n",
      "detecting: 223\n",
      "[ -84 -140 -160 -115 -161 -222 -191 -122 -171 -135 -155 -192 -183 -230\n",
      " -288 -283 -236 -251 -254 -148]\n",
      "detecting: -84\n",
      "[-163 -190 -111 -173 -169 -250 -111  -89 -113 -115 -174 -134  -47  -96\n",
      " -112  -78  -42  -58 -133 -140]\n",
      "detecting: -42\n",
      "[-586 -610 -628 -535 -590 -643 -608 -598 -562 -640 -660 -601 -635 -675\n",
      " -688 -636 -641 -590 -609 -568]\n",
      "detecting: -426\n",
      "[-745 -733 -716 -729 -764 -727 -784 -783 -731 -705 -727 -736 -697 -693\n",
      " -648 -731 -716 -674 -735 -721]\n",
      "detecting: -648\n",
      "[-1001 -1041 -1124 -1060 -1014  -997 -1032 -1043 -1018  -965  -935  -888\n",
      " -1009  -984  -968  -972  -954 -1023  -994  -939]\n",
      "detecting: -888\n",
      "[-1138 -1078 -1115 -1039 -1060 -1116 -1112 -1132 -1087 -1113 -1045 -1174\n",
      " -1117 -1128 -1142 -1085 -1138 -1089 -1136 -1116]\n",
      "detecting: -1039\n",
      "[-1130 -1130 -1099 -1161 -1180 -1106 -1120 -1155 -1273 -1121 -1164 -1212\n",
      " -1087 -1132 -1154 -1187 -1265 -1208 -1174 -1174]\n",
      "detecting: -1087\n",
      "[-1140 -1185 -1205 -1123 -1135 -1043 -1102 -1112 -1103 -1102 -1073 -1136\n",
      " -1168 -1082 -1089 -1120 -1141 -1086 -1021 -1119]\n",
      "detecting: -871\n",
      "[-1066 -1153 -1049 -1002 -1036 -1019 -1047 -1064 -1080 -1027 -1148 -1076\n",
      "  -986 -1110 -1002 -1104 -1050 -1050 -1011 -1019]\n",
      "detecting: -752\n",
      "[-684 -747 -818 -732 -750 -721 -760 -795 -692 -657 -736 -713 -688 -669\n",
      " -695 -666 -606 -663 -670 -663]\n",
      "detecting: -583\n",
      "[ -938  -906  -922  -907  -873  -919  -895  -850  -939 -1002  -991  -988\n",
      " -1014 -1033 -1027  -993 -1000 -1018 -1026 -1009]\n",
      "detecting: -836\n",
      "[-1096  -988  -964  -973  -950 -1021  -946  -888  -922  -946  -980  -906\n",
      "  -964  -988  -941  -981 -1019 -1050 -1010 -1051]\n",
      "detecting: -888\n",
      "[-1173 -1110 -1121 -1133 -1152 -1157 -1137 -1093 -1127 -1110 -1113 -1099\n",
      " -1152 -1128 -1163 -1146 -1171 -1231 -1125 -1125]\n",
      "detecting: -689\n",
      "[-747 -792 -851 -784 -826 -799 -797 -911 -837 -850 -888 -860 -853 -863\n",
      " -874 -864 -949 -907 -844 -862]\n",
      "detecting: -747\n",
      "[-1005  -976  -985  -894  -933  -930  -969 -1022  -954  -972  -917  -941\n",
      "  -955  -933  -914  -912  -852  -900  -898  -921]\n",
      "detecting: -122\n",
      "[-251 -236 -205 -250 -154 -188 -260 -220 -295 -221 -189 -168 -173 -224\n",
      " -275 -222 -261 -211 -227 -214]\n",
      "detecting: 29\n",
      "[ 16  34 -20  24  41  86  96  35  88  78  62  23  44  86 153 142 101 128\n",
      " 149 177]\n",
      "detecting: 519\n",
      "[370 352 389 331 417 404 343 403 446 385 368 374 336 329 316 388 409 452\n",
      " 375 431]\n",
      "detecting: 605\n",
      "[497 468 537 502 475 460 561 537 516 547 571 520 573 570 563 591 551 558\n",
      " 525 585]\n",
      "detecting: 809\n"
     ]
    }
   ],
   "source": [
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "while True:\n",
    "    data = stream.read(int(RECORD_DURATION * RATE/1000))\n",
    "    # print(data[:20])\n",
    "    audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "\n",
    "    print(audio_data[:20])\n",
    "    print(\"detecting:\", np.max(audio_data))\n",
    "\n",
    "    if np.max(audio_data) < DETECT_THRESHOLD:\n",
    "        continue\n",
    "\n",
    "    audio_data_detect = audio_data\n",
    "\n",
    "    data = stream.read(int(RECORD_DURATION * RATE))\n",
    "    # print(data[:20])\n",
    "    audio_data = np.frombuffer(data, dtype=np.int16)\n",
    "    \n",
    "    audio_data = np.concatenate((audio_data_detect, audio_data))\n",
    "\n",
    "    \n",
    "    # Reduce noise from the audio using noisereduce\n",
    "    audio_data = nr.reduce_noise(y=audio_data, sr=RATE)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160160\n"
     ]
    }
   ],
   "source": [
    "print(len(audio_data))\n",
    "\n",
    "sd.play(audio_data, RATE)\n",
    "sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: c:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary c:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, AutoProcessor\n",
    "import torch\n",
    "\n",
    "model_id = \"facebook/mms-1b-all\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.tokenizer.set_target_lang(\"cmn-script_simplified\")\n",
    "# model.load_adapter(\"cmn-script_simplified\")\n",
    "\n",
    "processor.tokenizer.set_target_lang(\"jpn\")\n",
    "model.load_adapter(\"jpn\")\n",
    "\n",
    "\n",
    "# processor.tokenizer.set_target_lang(\"eng\")\n",
    "# model.load_adapter(\"eng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supported_lang = processor.tokenizer.vocab.keys()\n",
    "\n",
    "# import re\n",
    "\n",
    "# # List of words\n",
    "# word_list = supported_lang\n",
    "\n",
    "# # Word you want to search for\n",
    "# search_word = \"jpn\"\n",
    "\n",
    "# # Define the regular expression pattern\n",
    "# pattern = r\".*\" + re.escape(search_word) + r\".*\"\n",
    "\n",
    "# # Loop through the list of words and search for the word\n",
    "# for word in word_list:\n",
    "#     if re.search(pattern, word):\n",
    "#         print(f\"'{search_word}' found in '{word}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   6   3 ... 127 108  91]\n"
     ]
    }
   ],
   "source": [
    "print(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor([audio_data*1.0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)\n",
    "# 'joe keton disapproved of films and buster also had reservations about the media'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flv台の天kです\n"
     ]
    }
   ],
   "source": [
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' You are the only one.',\n",
       " 'chunks': [{'text': ' You', 'timestamp': (29.98, 29.98)},\n",
       "  {'text': ' are', 'timestamp': (29.98, 29.98)},\n",
       "  {'text': ' the', 'timestamp': (29.98, 29.98)},\n",
       "  {'text': ' only', 'timestamp': (29.98, 29.98)},\n",
       "  {'text': ' one.', 'timestamp': (29.98, 29.98)}]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"openai/whisper-base\", device=device,  return_timestamps=\"word\"\n",
    "    # \"automatic-speech-recognition\", model=\"openai/whisper-medium-jp\", device=device,  return_timestamps=\"word\"\n",
    ")\n",
    "pipe(\n",
    "    audio_data,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"task\": \"transcribe\"},\n",
    "    chunk_length_s=30,\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.system(\"pip install git+https://github.com/openai/whisper.git\")\n",
    "# import gradio as gr\n",
    "import whisper\n",
    "\n",
    "# from share_btn import community_icon_html, loading_icon_html, share_js\n",
    "\n",
    "# model = whisper.load_model(\"small\")\n",
    "model = whisper.load_model(\"medium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio):\n",
    "    if type(audio) == str:\n",
    "        audio = whisper.load_audio(audio)\n",
    "    print(type(audio), audio.dtype, audio.shape)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    \n",
    "    # _, probs = model.detect_language(mel)\n",
    "    \n",
    "    options = whisper.DecodingOptions(fp16 = False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    \n",
    "    print(result.text)\n",
    "    return result.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 11 17 ...  4  2  5]\n",
      "<class 'numpy.ndarray'> float32 (160160,)\n",
      "今日の天気はいいです。何をしたのか?はぁ、悪い。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'今日の天気はいいです。何をしたのか?はぁ、悪い。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(audio_data)\n",
    "# print(audio_data.astype(np.float32))\n",
    "inference(audio_data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float32 (244736,)\n",
      "東京電極福島第一原発の処理水の環陽放出が24日にも始まる 放出に強く反発してきた中国からはすぐさま日本政府を批判する声があった\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'東京電極福島第一原発の処理水の環陽放出が24日にも始まる 放出に強く反発してきた中国からはすぐさま日本政府を批判する声があった'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(\"voice.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
