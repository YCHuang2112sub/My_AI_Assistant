{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f27547-ffca-4a4a-a116-3a59e4b9ece2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e556e17-781e-4af2-a5d3-d510acf26dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9feace96-4c51-4070-8f37-282406ae4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundRecorder:\n",
    "    def __init__(self):\n",
    "        self.recording = False\n",
    "        self.frames = []\n",
    "\n",
    "    def start_recording(self):\n",
    "        self.recording = True\n",
    "        self.frames = []\n",
    "        threading.Thread(target=self._record_audio).start()\n",
    "\n",
    "    def stop_recording(self):\n",
    "        self.recording = False\n",
    "\n",
    "    def _record_audio(self):\n",
    "        with sd.InputStream(callback=self._audio_callback):\n",
    "            sd.sleep(int(5 * 1000))  # Record for 5 seconds\n",
    "\n",
    "    def _audio_callback(self, indata, frames, time, status):\n",
    "        if self.recording:\n",
    "            self.frames.append(indata.copy())\n",
    "\n",
    "class ControlPanel:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Sound Recording Control Panel\")\n",
    "\n",
    "        self.recorder = SoundRecorder()\n",
    "\n",
    "        self.label = tk.Label(root, text=\"Press space to start recording sound...\")\n",
    "        self.label.pack(pady=20)\n",
    "\n",
    "        self.root.bind('<KeyPress>', self._on_key_press)\n",
    "\n",
    "    def _on_key_press(self, event):\n",
    "        if event.keysym == 'space':\n",
    "            if not self.recorder.recording:\n",
    "                self.label.config(text=\"Recording sound...\")\n",
    "                self.recorder.start_recording()\n",
    "            else:\n",
    "                self.label.config(text=\"Recording stopped\")\n",
    "                self.recorder.stop_recording()\n",
    "                self._save_audio()\n",
    "\n",
    "    def _save_audio(self):\n",
    "        if len(self.recorder.frames) > 0:\n",
    "            audio_data = np.concatenate(self.recorder.frames, axis=0)\n",
    "            sd.play(audio_data, self.recorder.frames[0].shape[1])\n",
    "            sd.wait()\n",
    "            self.label.config(text=\"Recording saved and played\")\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = ControlPanel(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b2c59-6c46-4590-94e9-90de2da43a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3687634-e402-4e0b-a57c-609767e34419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b89ce5-9bbc-4baf-b144-74d989d99c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80856c8-9469-4f97-a359-1d3d57113f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52ed36a-ed0a-49e6-98ca-d10894184a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.audio_utils import ffmpeg_read\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd72954c-53e1-484f-87da-1d686c219f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31612\\84807071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m pipe = pipeline(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "MODEL_NAME = \"openai/whisper-small\"\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"automatic-speech-recognition\",\n",
    "    model=MODEL_NAME,\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a123eb5a-f960-41f1-acf1-c3b7379113ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:40: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:40: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:41: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:41: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:42: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:42: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
      "C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\gradio\\blocks.py:699: UserWarning: Cannot load huggingface. Caught Exception: The space huggingface does not exist\n",
      "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:37: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  mic_transcribe = gr.Interface(\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:59: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Audio(source=\"upload\", optional=True, label=\"Audio file\", type=\"filepath\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:59: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Audio(source=\"upload\", optional=True, label=\"Audio file\", type=\"filepath\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:60: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:60: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:61: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:61: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:56: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  file_transcribe = gr.Interface(\n",
      "C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\gradio\\blocks.py:954: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n",
      "C:\\Users\\benve\\AppData\\Local\\Temp\\ipykernel_23996\\4144516193.py:83: GradioDeprecationWarning: The `enable_queue` parameter has been deprecated. Please use the `.queue()` method instead.\n",
      "  demo.launch(enable_queue=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n",
      "C:\\Users\\benve\\anaconda3\\envs\\py39\\lib\\site-packages\\transformers\\generation\\utils.py:1369: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Copied from https://github.com/openai/whisper/blob/c09a7ae299c4c34c5839a76380ae407e7d785914/whisper/utils.py#L50\n",
    "def format_timestamp(seconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"):\n",
    "    if seconds is not None:\n",
    "        milliseconds = round(seconds * 1000.0)\n",
    "\n",
    "        hours = milliseconds // 3_600_000\n",
    "        milliseconds -= hours * 3_600_000\n",
    "\n",
    "        minutes = milliseconds // 60_000\n",
    "        milliseconds -= minutes * 60_000\n",
    "\n",
    "        seconds = milliseconds // 1_000\n",
    "        milliseconds -= seconds * 1_000\n",
    "\n",
    "        hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "        return f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
    "    else:\n",
    "        # we have a malformed timestamp so just return it as is\n",
    "        return seconds\n",
    "\n",
    "\n",
    "def transcribe(file, task, return_timestamps):\n",
    "    outputs = pipe(file, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=return_timestamps)\n",
    "    text = outputs[\"text\"]\n",
    "    if return_timestamps:\n",
    "        timestamps = outputs[\"chunks\"]\n",
    "        timestamps = [\n",
    "            f\"[{format_timestamp(chunk['timestamp'][0])} -> {format_timestamp(chunk['timestamp'][1])}] {chunk['text']}\"\n",
    "            for chunk in timestamps\n",
    "        ]\n",
    "        text = \"\\n\".join(str(feature) for feature in timestamps)\n",
    "    return text\n",
    "\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "mic_transcribe = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\", optional=True),\n",
    "        gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
    "        gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    layout=\"horizontal\",\n",
    "    theme=\"huggingface\",\n",
    "    title=\"Whisper Demo: Transcribe Audio\",\n",
    "    description=(\n",
    "        \"Transcribe long-form microphone or audio inputs with the click of a button! Demo uses the\"\n",
    "        f\" checkpoint [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME}) and 🤗 Transformers to transcribe audio files\"\n",
    "        \" of arbitrary length.\"\n",
    "    ),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "file_transcribe = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"upload\", optional=True, label=\"Audio file\", type=\"filepath\"),\n",
    "        gr.inputs.Radio([\"transcribe\", \"translate\"], label=\"Task\", default=\"transcribe\"),\n",
    "        gr.inputs.Checkbox(default=False, label=\"Return timestamps\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    layout=\"horizontal\",\n",
    "    theme=\"huggingface\",\n",
    "    title=\"Whisper Demo: Transcribe Audio\",\n",
    "    description=(\n",
    "        \"Transcribe long-form microphone or audio inputs with the click of a button! Demo uses the\"\n",
    "        f\" checkpoint [{MODEL_NAME}](https://huggingface.co/{MODEL_NAME}) and 🤗 Transformers to transcribe audio files\"\n",
    "        \" of arbitrary length.\"\n",
    "    ),\n",
    "    # examples=[\n",
    "    #     [\"./example.flac\", \"transcribe\", False],\n",
    "    #     [\"./example.flac\", \"transcribe\", True],\n",
    "    # ],\n",
    "    cache_examples=True,\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "with demo:\n",
    "    gr.TabbedInterface([mic_transcribe, file_transcribe], [\"Transcribe Microphone\", \"Transcribe Audio File\"])\n",
    "\n",
    "demo.launch(enable_queue=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b6576f-2268-472f-b660-bc542670706f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
